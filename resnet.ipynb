{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8091620",
   "metadata": {},
   "source": [
    "# ***ResNet Architecture***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63324cdd",
   "metadata": {},
   "source": [
    "- **ResNet** is motivated by the difficulty of training very deep networks due to **vanishing gradients**. It introduces *residual learning* through skip connections.\n",
    "- *Residual Connections* allow gradients to flow directly through identity paths, enabling the training of deeper models without degradation. This helps the network learn residual functions instead of full mappings, improving convergence and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f7e83",
   "metadata": {},
   "source": [
    "## Importing libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307caed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52808046",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/Difference.png\" alt = \"ResBlock\" width=\"70%\"/> <br>\n",
    "  <em> Left: block for ResNet-\n",
    "34. Right: bottleneck for ResNet-50/101/152. </em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca15a3",
   "metadata": {},
   "source": [
    "## ***ResNet 50+***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247a028",
   "metadata": {},
   "source": [
    "### Bottleneck block class (ResNet 50/101/152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18797762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample = None, stride = 1):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = 1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding = 1), #This is where the spatial size may be halved/changed, often on the 1st block\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels *self.expansion, kernel_size=1, stride = 1, padding = 0),\n",
    "            nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        )\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward (self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.model(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        \n",
    "        x+= identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efee658",
   "metadata": {},
   "source": [
    "### Making layers of blocks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c16e261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer(ResBlock, blocks,in_channels, planes, stride=1):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        #Perform downsampling when the dimensions do not match or stride is not 1\n",
    "        if stride!= 1 or in_channels != planes*ResBlock.expansion:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,planes*ResBlock.expansion, kernel_size=1, stride = stride, padding = 0),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        #Compute the 1st block of the layer that requires downsampling\n",
    "        layers.append(ResBlock(in_channels, planes, identity_downsample= identity_downsample, stride = stride)) \n",
    "        in_channels = planes *ResBlock.expansion\n",
    "\n",
    "        for i in range (blocks -1):\n",
    "            layers.append(ResBlock(in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers) #This means that nn.Sequential(block1, block2, block3, block4..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4fe34",
   "metadata": {},
   "source": [
    "### ResNet 50+ class defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, block_list, num_classes, num_channels = 3, planes = [64,128,256,512] ):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.planes = planes\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.planes[0], kernel_size=7, stride = 2, padding = 3) #[64,112,112]\n",
    "        self.BN1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3,stride = 2, padding = 1) #[64,56,56]\n",
    "        \n",
    "        self.layer_1 = make_layer(ResBlock, block_list[0],self.planes[0], planes=self.planes[0]) #Output: [256,56,56]\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range (1,len(block_list)):\n",
    "            layer = make_layer(ResBlock, block_list[i], self.planes[i-1]*ResBlock.expansion, self.planes[i], stride =2)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1)) #(B,C,1,1) This pools each feature map individually into a 1x1 feature map\n",
    "        self.fc = nn.Linear(self.planes[3]*ResBlock.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.BN1(self.conv1(x)))\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.layer_1(x)\n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.reshape(x.shape[0], -1) #Flatten the tensor of 4 dimensions [B,C,1,1] to [B,C] of 2 dimensions including the batch size\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def train_batch(self, x, y, optimizer, loss_fn):\n",
    "        self.train()\n",
    "        prediction = self(x) #same as self.forward(x)\n",
    "        batch_loss = loss_fn(prediction, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return batch_loss.item(), prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608aaf4",
   "metadata": {},
   "source": [
    "## ***ResNet 18/34*** (or lighter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf6bd0",
   "metadata": {},
   "source": [
    "### Residual Block for the 18/34-layers ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7329f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample = None, stride = 1):\n",
    "        super(Block,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride = 1, padding = 1), #For changes in spatial size (Downsample)\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward (self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.model(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        \n",
    "        x+= identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6d4b9",
   "metadata": {},
   "source": [
    "### Making layers of blocks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a68e21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layer_ (ResBlock, blocks, in_channels, out_channels, stride = 1):\n",
    "    identity_downsample = None\n",
    "    layers = []\n",
    "    if stride!= 1 or in_channels !=  out_channels:\n",
    "        identity_downsample = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = stride),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    layers.append(ResBlock(in_channels,out_channels, identity_downsample = identity_downsample, stride = stride))\n",
    "    for i in range (blocks-1):\n",
    "        layers.append(ResBlock(out_channels,out_channels))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b10edc",
   "metadata": {},
   "source": [
    "### Lite ResNet (18/34) class defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb17887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_lite(nn.Module):\n",
    "    def __init__ (self, ResBlock, block_list, num_classes, num_channels = 3, planes = [64,128,256,512]):\n",
    "        super(ResNet_lite, self).__init__()\n",
    "        self.planes = planes\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.planes[0], kernel_size=7, stride = 2, padding = 3)\n",
    "        self.BN1 = nn.BatchNorm2d(self.planes[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1) #Downsample \n",
    "\n",
    "        self.layer1 = make_layer_(ResBlock,block_list[0], self.planes[0], self.planes[0])\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range (1,len(block_list)):\n",
    "            layer = make_layer_(ResBlock, block_list[i], self.planes[i-1], self.planes[i], stride =2)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.planes[3], num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.BN1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.layer1(x)\n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.reshape(x.shape[0], -1) #Flatten the tensor of 4 dimensions [B,C,1,1] to [B,C] of 2 dimensions including the batch size\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def train_batch(self, x, y, optimizer, loss_fn):\n",
    "        self.train()\n",
    "        prediction = self(x) #same as self.forward(x)\n",
    "        batch_loss = loss_fn(prediction, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return batch_loss.item(), prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792c347",
   "metadata": {},
   "source": [
    "## Defining Residual Networks of different depths: 18/34/50/101/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6904d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(num_classes = 100, num_in_channels = 3):\n",
    "    block_list = [2,2,2,2]\n",
    "    return ResNet_lite(Block,block_list, num_classes, num_in_channels)\n",
    "\n",
    "def ResNet34(num_classes = 100, num_in_channels = 3):\n",
    "    block_list = [3,4,6,3]\n",
    "    return ResNet_lite(Block, block_list, num_classes, num_in_channels)\n",
    "\n",
    "def ResNet50(num_classes = 1000, num_in_channels = 3):\n",
    "    block_list = [3,4,6,3]\n",
    "    return ResNet(Bottleneck, block_list, num_classes, num_in_channels)\n",
    "\n",
    "def ResNet101(num_classes = 1000, num_in_channels = 3):\n",
    "    block_list = [3,4,23,3]\n",
    "    return ResNet(Bottleneck, block_list, num_classes, num_in_channels)\n",
    "\n",
    "def ResNet152(num_classes = 1000, num_in_channels = 3):\n",
    "    block_list = [3,8,36,3]\n",
    "    return ResNet(Bottleneck, block_list, num_classes, num_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3623703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000]) torch.Size([2, 3, 224, 244])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = ResNet50()\n",
    "    x = torch.randn(2,3,224,244)\n",
    "    y = net(x).to(device)\n",
    "    print( y.shape, x.shape)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
